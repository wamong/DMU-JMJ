인공신경망

1. 	활성화 함수 그래프 모양
	시그모이드 함수
	 - S자 - 함수값
	 - 코끼리삼킨보아뱀모양 - 미분값

	렐루 함수
	 - 함수값은 균일하게 상승
	 - 미분값은 평행선

	하이퍼볼릭탄젠트 함수
	 - 시그모이드 보다 굴곡이 큼

	소프트플러스 함수
	 - 곡선을 그리며 상승

2.	a) 소프트맥스 함수
	2개 이상 확률을 구할때 사용
	(시그모이드는 2개확률을 구함)
	소프트맥스 함수일때 마지막 컴파일부분의 
	손실함수부분이 바뀜
		loss -> categorical_crossentropy

	시그모이드 손실함수는
	binary_cossentropy

	b) 과적합
	 => 모델이 학습데이터 셋 안에서는 일정 수준 이상의 예측정확도를 보이지만
	세로은 데이터에 적용하면 잘맞지 않는것을 의미
	- 층이 너무 많거나 변수가 복잡하거나 테스트셋과 학습셋이 중복될때 생김
	
	c) 원-핫인코딩/get_dummies()
	=> 문자열을 숫자로 바꿔주는 코딩
	- 여러개의 값으로 된 문자열을 0과 1로 만들어주는 것

	d) KFold()
	=> K겹 교차검증 
	- 데이터셋을 여러개로 나누어 하나씩 테스트셋으로 사용하고
	 나머지를 모두 합해서 학습셋으로 사용하는 방법
	
	e) 사이킷런 용어개념 이해 (scikit_learn)
	- 파이썬 필수 라이브러리
	=> 파이썬을 대표하는 머신러닝 라이브러리

3. 딥러닝 코드 중 인공신경망 구조 설정 부분 이해
	입력층 
	 - 첫번째 은닉층
	  - ex) model = seqential()
		  model.add(Dense(30, input_dim=16, activation='relu'))
		  model.add(Dense(1, actiavtion='sigmoid')
		  
	은닉층
	
	출력층
	 - model.add의 마지막줄이 출력층
	
4. model.add(), model.compile(), model.fit() 함수 패러미터 설정
	model.add = 입력,은닉,출력
	model.compile = 모델이 효과적으로 구현될수있게 여러가지 환경을 설정해주는 부분
	model.fit = 모델을 실행할때 사용
		ex) history = model.fit
			(X, y, epochs = 5, batch_size = 16)

5. Data 분리 방법 (학습셋/검증셋/테스트셋)
학습셋 = 신경망 구조 만든것을 학습
검증셋 = 모델을 검증함
테스트셋 = 학습된 모델을 시험함

		데이터셋
		100%
	학습셋과 	테스트셋
	80%		20%
학습셋	검증셋
75%		25%
학습셋	검증셋	테스트셋
60%		20%		20%

validation_split=0.25

6. 딥러닝 수행 파이썬 코드예제 (14장 코드 집중 분석 필요)



model = Sequential 	-> 연속적인, 수열 이라는 뜻 (구조 생성시 선언)
Dense 		        -> 노드들을 연결하는 명령어

model.compile 		-> 위의 구조를 포장해 주는 느낌쓰

7장 7, 11, 21p
8장 33p
9장 19,23p
10장 6~7p 코드, 해석 11~15p, 18,19,21p
11장 25,30p
12장 19~22,28,30~35p
13장 16~65p
14장 9~10, 11~18p(*13p*),22~23p,40~48p
7~14장 확인 후 15장.